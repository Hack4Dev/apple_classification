{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f893407-c45b-4a97-8906-702e72754885",
   "metadata": {},
   "source": [
    "# Tutorial 5: RFE on all features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7f0a3d-c257-43a6-84d1-643324886063",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a661a3-77c9-4e5c-ba18-72f455a25c91",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21305f5-293e-4bbe-bfd8-ec8d01787f48",
   "metadata": {},
   "source": [
    "Hello, this notebook will show how to use RFE to perform further feature selection, as we found that most features are very highly correlated, therfore we would need to remove those using the tool that we mentioned above. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45456717-90bf-44c1-be0b-f2ad9314737f",
   "metadata": {},
   "source": [
    "first, let us call the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbec0b60-3e98-432e-9de6-fb444ce4c70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r df_input_RG\n",
    "%store -r y_RG\n",
    "%store -r df_RG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc2bd9ee-bb2c-453d-97fb-7104a64d8120",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_RG = y_RG.map({'S': 1, 'B': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a963998-c26e-40b6-bbfc-d5c1110dd9bf",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea3bba6-fa62-43bf-a543-fb088617b9cf",
   "metadata": {},
   "source": [
    "calling some packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4be29664-f490-4ef1-a263-7fcaaa093c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python packages \n",
    "import pandas as pd # for importing data into data frame format\n",
    "import seaborn as sns # For drawing useful graphs, such as bar graphs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08c43a3-5668-4360-92fb-7d28a1bdb3a0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785b56a0-0772-4cc2-a2f6-34a9fe598b80",
   "metadata": {},
   "source": [
    "<b><i> Data splitting </i></b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24b557bd-4d21-4767-bd55-f27cfbfdd8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split( df_input_RG, y_RG, test_size = 0.3, random_state=3, stratify=y_RG) # train and valid sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5acc93a2-c050-4d22-8e18-c37c179060a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(393, 2074)\n",
      "(169, 2074)\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.shape)\n",
    "print(Xtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8fc28e-022b-4cd0-be84-e590c7774324",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d924da-a97b-4897-a2b0-b21a9efc176e",
   "metadata": {},
   "source": [
    "<b><i> import the best 50 features across 4 diffrint ways </i></b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81d228ce-d55b-4806-b9c1-0f0ca7e74351",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFS\n",
    "rfsImp = [1312.065, 874.121, 1312.729, 873.826, 1313.394, 882.151, 1314.06, 1503.852, 1311.401, 894.322, 1310.738, 894.014, 1308.754, 1309.415, 898.662, 1509.104, 1308.093, 900.535, 1310.076, 1502.98, 2480.996, 1508.226, 1307.433, 900.848, 1306.774, 900.222, 1306.116, 1509.983, 1301.526, 904.936, 1300.873, 899.91, 1507.349, 1302.18, 904.62, 1314.726, 2483.372, 1506.473, 1300.221, 904.305, 1305.458, 1512.626, 912.58, 1302.834, 1299.569, 898.351, 1502.109, 1304.801, 1920.475, 903.989]\n",
    "\n",
    "rfsImp_200 = [1300.873, 870.89, 1302.18, 860.484, 1304.801, 853.684, 1322.776, 1497.77, 1296.32, 884.257, 1295.672, 884.86, 1294.379, 890.942, 1293.088, 1509.104, 887.283, 1291.156, 1291.799, 891.555, 1289.871, 895.558, 1286.67, 1496.906, 1914.801, 1508.226, 1285.394, 850.046, 1287.949, 910.657, 1509.983, 1284.758, 908.742, 1281.582, 896.797, 1282.85, 1498.636, 2485.753, 1282.216, 1507.349, 1279.684, 1277.163, 842.04, 1510.863, 1278.422, 1275.906, 926.274, 1514.393, 2425.295, 1275.278]\n",
    "\n",
    "\n",
    "# SFS\n",
    "sfsImp = [1840.057, 1486.606, 904.62, 1168.909, 888.5, 980.575, 1152.285, 1522.396, 1857.192, 1861.192, 976.513, 882.451, 1136.126, 1523.291, 1399.159, 1123.815, 1022.335, 1028.01, 1126.745, 1127.235, 948.99, 953.878, 1862.529, 1023.95, 1125.278, 1122.841, 946.565, 954.58, 951.777, 1127.725, 1125.767, 1537.747, 1026.788, 1541.403, 1120.9, 1019.521, 953.527, 952.827, 1538.659, 1025.57, 949.686, 952.126, 1126.256, 1539.573, 951.428, 950.033, 951.078, 952.476, 1025.164, 1023.142]\n",
    "\n",
    "sfsImp_200 = [1992.806, 1376.867, 837.416, 1458.178, 1246.462, 870.89, 908.742, 926.274, 943.465, 1053.919, 934.285, 1046.686, 1056.065, 1046.263, 1070.454, 1098.577, 1281.582, 1155.366, 1510.863, 968.85, 1478.13, 1142.636, 2485.753, 890.942, 992.588, 1509.104, 998.322, 1022.738, 1124.79, 1111.767, 1018.319, 1017.121, 1044.998, 1997.412, 1968.596, 1032.513, 1030.461, 1521.503, 1256.124, 1239.905, 1129.691, 1011.17, 1025.976, 1013.146, 884.86, 895.558, 887.283, 1172.08, 1180.082, 896.797]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b18a7b7d-d597-42b3-87a4-89e5cea0b0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFS\n",
    "rfs = [rfsImp, [8, 10, 37, 50]]\n",
    "rfs_200 = [rfsImp_200, [3, 10, 20, 50]]\n",
    "# SFS\n",
    "sfs = [sfsImp, [3, 10, 37, 50]]\n",
    "sfs_200 = [sfsImp_200, [5, 10, 20, 50]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b820c2b-3c0d-4095-a15f-02736091fa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [ rfs, rfs_200, sfs, sfs_200]\n",
    "features_name = [ \"rfs\", \"rfs_200\", \"sfs\", \"sfs_200\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ff8490-cd9e-4867-8762-4e48b9c9850b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbd6c0a-9627-493c-bcdf-6f874bc2b02a",
   "metadata": {},
   "source": [
    "<b><i> models </i></b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41a59e84-c5f3-4d3e-87bb-9e9e50957a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from numpy import random as np_random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5529da7-4963-4fc2-93d8-a56742b292b6",
   "metadata": {},
   "source": [
    "first let us define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e6df99c-4c0a-4abf-a4da-1751e465dc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "svm = SVC(kernel=\"rbf\")\n",
    "rf = RandomForestClassifier(random_state=1)\n",
    "xgb = XGBClassifier(random_state=1)\n",
    "knns = KNeighborsClassifier()\n",
    "anns = MLPClassifier(max_iter=3000, random_state=1, activation = 'relu', solver = 'sgd')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f3a81b-5227-444e-a8fe-bd5bc0b78e87",
   "metadata": {},
   "source": [
    "defining the hyper-paramter per model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85500a7c-45d4-46ba-be11-32a103661274",
   "metadata": {},
   "outputs": [],
   "source": [
    "solvers = ['newton-cg', 'liblinear']\n",
    "penalty = ['l2']\n",
    "c_values = [1000, 100, 10, 1.0, 0.1, 0.01, 0.001]\n",
    "lr_par = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "\n",
    "##############################\n",
    "C_range = np.logspace(-1, 10, 20) # define a set of values for the parameter C\n",
    "gamma_range = np.logspace(-9, 3, 20) # define a set of values for the parameter gamma\n",
    "\n",
    "svm_par = dict(gamma=gamma_range, C=C_range)\n",
    "\n",
    "#########################\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "\n",
    "#max_features = ['sqrt', 'log2']\n",
    "\n",
    "rf_par = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "#######################\n",
    "# https://www.kaggle.com/code/tilii7/hyperparameter-grid-search-with-xgboost/notebook\n",
    "xgb_par = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5, 9],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5, 8]\n",
    "        }\n",
    "##################################\n",
    "n_neighbors = range(1, 30, 2)\n",
    "weights = ['uniform', 'distance']\n",
    "metric = ['euclidean', 'manhattan', 'minkowski']\n",
    "\n",
    "knns_par = dict(n_neighbors=n_neighbors,weights=weights,metric=metric)\n",
    "################\n",
    "anns_par = {\n",
    "    'hidden_layer_sizes': [(3,3),(5,5),(8,3)],\n",
    "#     'activation': ['relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.001,0.01,0.1, 0.05, 0.005 , 0.005, 0.00005],\n",
    "#     'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "204c32a1-69f9-44d4-b2fd-776a1226006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [[lr, 'lr', 14], [svm, 'svm', 15], [rf, 'rf', 30], [xgb, 'xgb', 30], [knns, 'knns', 30], [anns, 'anns', 30]]\n",
    "par = [lr_par, svm_par, rf_par, xgb_par, knns_par, anns_par]\n",
    "\n",
    "# models = [[lr, 'lr', 14]]\n",
    "# par = [lr_par]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf860784-c2a6-4504-ae80-46c048ed5bc6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b118d6c7-1287-4ba3-8c63-fb0957fc8b0d",
   "metadata": {},
   "source": [
    "<b><i> training, TESTING RESULTS </i></b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e3b8d6b-9990-4960-8974-1e53771f9296",
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.ml_acc import get_accuracy_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d80c301-2bce-444d-bfba-eb2a2282bc51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr\n",
      "0\n",
      "[1312.065, 874.121, 1312.729, 873.826, 1313.394, 882.151, 1314.06, 1503.852, 1311.401, 894.322, 1310.738, 894.014, 1308.754, 1309.415, 898.662, 1509.104, 1308.093, 900.535, 1310.076, 1502.98, 2480.996, 1508.226, 1307.433, 900.848, 1306.774, 900.222, 1306.116, 1509.983, 1301.526, 904.936, 1300.873, 899.91, 1507.349, 1302.18, 904.62, 1314.726, 2483.372, 1506.473, 1300.221, 904.305, 1305.458, 1512.626, 912.58, 1302.834, 1299.569, 898.351, 1502.109, 1304.801, 1920.475, 903.989]\n",
      "[1312.065, 874.121, 1312.729, 873.826, 1313.394, 882.151, 1314.06, 1503.852]\n"
     ]
    }
   ],
   "source": [
    "num_ml_tools = len(par)\n",
    "ml_dicts = {}\n",
    "\n",
    "for m, par in zip(models, par):\n",
    "    key_model = str(m[1])\n",
    "    ml_dicts[key_model] = {}\n",
    "    print(key_model)\n",
    "    for ind_imp in range (4):\n",
    "        print(ind_imp)\n",
    "        for f, f_name in zip(features, features_name):\n",
    "            print(f[0])\n",
    "            featArry = f[0]\n",
    "            featArry2 = featArry[:f[1][ind_imp]]\n",
    "            xtr =  Xtrain[featArry2]\n",
    "            print(list(xtr.columns))\n",
    "            \n",
    "\n",
    "            xte =  Xtest[featArry2]\n",
    "            results = get_accuracy_ml (m[0], m[2], par, np.array(xtr), np.array(Ytrain), np.array(xte), np.array(Ytest)) # to get the accuracies for the ml model\n",
    "\n",
    "            key_feat = str(f_name)+\",\"+str(f[1][ind_imp])\n",
    "            print(key_feat)\n",
    "            print()\n",
    "            ml_dicts[key_model][key_feat] = {}\n",
    "\n",
    "            ml_dicts[key_model][key_feat]['tot_acc'] = results[0]\n",
    "            ml_dicts[key_model][key_feat]['jack_train'] = results[1]\n",
    "            ml_dicts[key_model][key_feat]['jack_test'] = results[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e028ed56-e150-43b1-b5c4-75d3e51cde3e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00226726-46c7-4e75-aa41-87161f671a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('ml_gs_test.txt', 'w') as file:\n",
    "     file.write(json.dumps(ml_dicts)) # use `json.loads` to do the reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b24007d-c3a6-4810-87dc-02ba21d4e113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('ml_rg_test.txt') as f:\n",
    "    data = f.read()\n",
    "    \n",
    "ml_dicts = json.loads(data)\n",
    "\n",
    "with open('base_rg.txt') as f:\n",
    "    data = f.read()\n",
    "    \n",
    "baseDict = json.loads(data)\n",
    "baseDict['lr'].keys()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611d35b7-2aef-4199-b41c-782022887615",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(baseDict['lr'].keys()    )\n",
    "print(ml_dicts['lr'].keys()    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dfeb61-93a6-4a30-9380-10c3be28ef46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.calculate_jack import jack_SD # importing the baseline code from source.basline file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8244e56-7f79-4af0-a4c9-d6a98f15bab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_all = []\n",
    "for m, d in zip (models, ml_dicts.keys()):\n",
    "    acc_arr = [] \n",
    "    sd_arr = [] \n",
    "    keys = []\n",
    "    # print(ml_dicts[d])\n",
    "    for key in ml_dicts[d].keys():\n",
    "        if 'rfs' not in key:\n",
    "            print(key)    \n",
    "            keys.append(key)\n",
    "            acc_arr.append(ml_dicts[d][key][ 'tot_acc' ]) # append total accuracy to an array\n",
    "            sd_train = jack_SD(np.zeros( len(ml_dicts[d][key][ 'jack_train' ]) ), ml_dicts[d][key][ 'jack_train' ])[0]\n",
    "            sd_test = jack_SD(np.zeros( len(ml_dicts[d][key][ 'jack_test' ]) ), ml_dicts[d][key][ 'jack_test' ])[0]\n",
    "            sd = np.sqrt( np.array((sd_train**2)) + np.array((sd_test**2)))\n",
    "            sd_arr.append(sd) # append sd_arr to an array\n",
    "    \n",
    "    arr_all.append([keys, acc_arr, sd_arr])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b34cb1-9a19-4186-b561-248271913dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['blue', 'purple', 'green', 'orange', 'red', 'brown']\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.title( \"Precision  for different features with the SD\", fontweight ='bold', fontsize =12)\n",
    "plt.xlabel(\"Features\", fontweight ='bold', fontsize =12)\n",
    "plt.ylabel(\"Precision\", fontweight ='bold', fontsize =12)\n",
    "\n",
    "count = 0\n",
    "n = len(colors)-1\n",
    "\n",
    "space = []\n",
    "tickFeat = []\n",
    "\n",
    "for result, model, color in zip(arr_all, models, colors):\n",
    "    a = np.linspace(n*count, n*(1+count)-2,len(arr_all[0][0]))\n",
    "    # a = np.linspace(0, 1,len(arr_all[0][0]))\n",
    "    \n",
    "    print(a)\n",
    "    space.extend(a)\n",
    "    tickFeat.extend(result[0])\n",
    "    plt.errorbar( a, result[1], result[2], fmt='o', label =model[1], color = color)\n",
    "    count += 1\n",
    "\n",
    "plt.xticks(space, tickFeat, rotation = 'vertical',  fontsize =12)\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35300c52-d061-4cd6-bb80-cb0f440d0e86",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d520d1-813d-478a-81d3-65f15ebd6808",
   "metadata": {},
   "source": [
    "Relative perfromance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da14d268-5593-4fe4-89ed-6d10ec9c3296",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_diff_all = []\n",
    "\n",
    "for m, m_key in zip (models, ml_dicts.keys()):\n",
    "    acc_diff_arr = [] \n",
    "    sd_diff_arr = [] \n",
    "    keys = []\n",
    "    for f_key in ml_dicts[m_key].keys():\n",
    "        if 'rfs' not in f_key:\n",
    "            print(f_key)\n",
    "            keys.append(f_key)\n",
    "            value = f_key.split(',')\n",
    "            acc_diff_arr.append( ml_dicts[m_key][f_key][ 'tot_acc' ] - baseDict['lr']['lr, all'][ 'tot_acc' ]  )\n",
    "\n",
    "            sd_train = jack_SD( baseDict['lr']['lr, all'][ 'jack_train' ], ml_dicts[m_key][f_key]['jack_train'] )[0]\n",
    "            sd_test = jack_SD(  baseDict['lr']['lr, all'][ 'jack_test' ],  ml_dicts[m_key][f_key]['jack_test']   )[0]\n",
    "\n",
    "            sd = np.sqrt( np.array((sd_train**2)) + np.array((sd_test**2)))\n",
    "            sd_diff_arr.append(sd) # append sd_arr to an array\n",
    "    \n",
    "    arr_diff_all.append([keys, acc_diff_arr, sd_diff_arr]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da81074-26d2-4c4b-83ff-b8446e19c0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['blue', 'purple', 'green', 'orange', 'red', 'brown']\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.title( \"Precision  differences for ML methods versus LR_all for feature setsD\", fontweight ='bold', fontsize =12)\n",
    "plt.xlabel(\"Features\", fontweight ='bold', fontsize =12)\n",
    "plt.ylabel(\"Precision  difference\", fontweight ='bold', fontsize =12)\n",
    "\n",
    "count = 0\n",
    "n = len(colors)-0.5\n",
    "space = []\n",
    "tickFeat = []\n",
    "\n",
    "for result, model, color in zip(arr_diff_all, models, colors):\n",
    "    a = np.linspace(n*count, n*(1+count)-2,len(arr_diff_all[0][0]))\n",
    "    space.extend(a)\n",
    "    tickFeat.extend(result[0])\n",
    "    plt.errorbar( a, result[1], result[2], fmt='o', label =model[1], color = color)\n",
    "    count += 1\n",
    "    \n",
    "plt.plot(np.array(space), np.zeros(len(arr_diff_all[0][0])*6), color = 'Black')        \n",
    "plt.xticks(space, tickFeat, rotation = 'vertical',  fontsize =12)\n",
    "plt.ylim(-1, .5)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3be428a-f4d5-4827-92aa-15d0843838d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96003a3e-a3ec-4521-9854-be09df8d7806",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apple_kernel",
   "language": "python",
   "name": "apple_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
