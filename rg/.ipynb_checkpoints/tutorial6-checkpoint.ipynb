{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f893407-c45b-4a97-8906-702e72754885",
   "metadata": {},
   "source": [
    "# Tutorial 6: RFE on the best 400 features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7f0a3d-c257-43a6-84d1-643324886063",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a661a3-77c9-4e5c-ba18-72f455a25c91",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21305f5-293e-4bbe-bfd8-ec8d01787f48",
   "metadata": {},
   "source": [
    "Hello, this notebook will show how to use RFE to perform further feature selection, as we found that most features are very highly correlated, therfore we would need to remove those using the tool that we mentioned above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01ee051f-c3d0-46e5-b921-84901db973da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45456717-90bf-44c1-be0b-f2ad9314737f",
   "metadata": {},
   "source": [
    "first, let us call the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbec0b60-3e98-432e-9de6-fb444ce4c70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r df_input_RG\n",
    "%store -r y_RG\n",
    "%store -r df_RG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc2bd9ee-bb2c-453d-97fb-7104a64d8120",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_RG = y_RG.map({'S': 1, 'B': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a963998-c26e-40b6-bbfc-d5c1110dd9bf",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea3bba6-fa62-43bf-a543-fb088617b9cf",
   "metadata": {},
   "source": [
    "calling some packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4be29664-f490-4ef1-a263-7fcaaa093c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python packages \n",
    "import pandas as pd # for importing data into data frame format\n",
    "import seaborn as sns # For drawing useful graphs, such as bar graphs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08c43a3-5668-4360-92fb-7d28a1bdb3a0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785b56a0-0772-4cc2-a2f6-34a9fe598b80",
   "metadata": {},
   "source": [
    "<b><i> Data splitting </i></b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24b557bd-4d21-4767-bd55-f27cfbfdd8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split( df_input_RG, y_RG, test_size = 0.3, random_state=3, stratify=y_RG) # train and valid sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5acc93a2-c050-4d22-8e18-c37c179060a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(393, 2074)\n",
      "(169, 2074)\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.shape)\n",
    "print(Xtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8fc28e-022b-4cd0-be84-e590c7774324",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2c9fb6-2e96-47e3-8469-6e09beaecf49",
   "metadata": {},
   "source": [
    "<b><i> get the best N features </i></b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6266887b-9436-4e2a-8171-a17156afd675",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r featImp_RG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "923b7f48-f1a0-417f-8627-9fac12335347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1316 1284 1093 1290   60 1034 1068 1029 1070 1107]\n"
     ]
    }
   ],
   "source": [
    "arrimp = np.array(featImp_RG).mean(0)\n",
    "sorted_idx = arrimp.argsort()\n",
    "print(sorted_idx[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee471b52-e1ce-4089-b174-da8dc69196fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([1089.345, 1063.429,  962.734,  965.601,   914.19, 1076.231, 1250.068,\n",
       "        960.238, 1267.175, 1047.108,\n",
       "       ...\n",
       "       1445.173, 1419.847, 1285.394, 1424.528,  850.046, 1248.864, 1269.657,\n",
       "       1245.863, 1270.902, 1294.379],\n",
       "      dtype='object', length=400)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_ordered = df_input_RG.columns[sorted_idx][-400:]\n",
    "cols_ordered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43148aed-4094-4725-929c-49df2386b9b6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7b866b9-ee31-4b8f-86d6-3aca428a092a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1089.345</th>\n",
       "      <th>1063.429</th>\n",
       "      <th>962.734</th>\n",
       "      <th>965.601</th>\n",
       "      <th>914.190</th>\n",
       "      <th>1076.231</th>\n",
       "      <th>1250.068</th>\n",
       "      <th>960.238</th>\n",
       "      <th>1267.175</th>\n",
       "      <th>1047.108</th>\n",
       "      <th>...</th>\n",
       "      <th>1445.173</th>\n",
       "      <th>1419.847</th>\n",
       "      <th>1285.394</th>\n",
       "      <th>1424.528</th>\n",
       "      <th>850.046</th>\n",
       "      <th>1248.864</th>\n",
       "      <th>1269.657</th>\n",
       "      <th>1245.863</th>\n",
       "      <th>1270.902</th>\n",
       "      <th>1294.379</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>1.028729</td>\n",
       "      <td>1.030634</td>\n",
       "      <td>1.004159</td>\n",
       "      <td>1.004502</td>\n",
       "      <td>1.044561</td>\n",
       "      <td>1.030239</td>\n",
       "      <td>0.965256</td>\n",
       "      <td>1.005951</td>\n",
       "      <td>0.966981</td>\n",
       "      <td>1.025428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.796700</td>\n",
       "      <td>0.816613</td>\n",
       "      <td>0.965266</td>\n",
       "      <td>0.808167</td>\n",
       "      <td>1.052470</td>\n",
       "      <td>0.965650</td>\n",
       "      <td>0.966705</td>\n",
       "      <td>0.965603</td>\n",
       "      <td>0.966063</td>\n",
       "      <td>0.963941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>-0.904164</td>\n",
       "      <td>-0.908347</td>\n",
       "      <td>-0.839096</td>\n",
       "      <td>-0.835209</td>\n",
       "      <td>-0.930014</td>\n",
       "      <td>-0.908296</td>\n",
       "      <td>-0.728967</td>\n",
       "      <td>-0.843634</td>\n",
       "      <td>-0.730239</td>\n",
       "      <td>-0.900330</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.452495</td>\n",
       "      <td>-0.447041</td>\n",
       "      <td>-0.722030</td>\n",
       "      <td>-0.446465</td>\n",
       "      <td>-0.930544</td>\n",
       "      <td>-0.728422</td>\n",
       "      <td>-0.730134</td>\n",
       "      <td>-0.727560</td>\n",
       "      <td>-0.729684</td>\n",
       "      <td>-0.712608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>1.122145</td>\n",
       "      <td>1.130994</td>\n",
       "      <td>1.050363</td>\n",
       "      <td>1.048614</td>\n",
       "      <td>1.148173</td>\n",
       "      <td>1.129931</td>\n",
       "      <td>0.994477</td>\n",
       "      <td>1.052448</td>\n",
       "      <td>0.996704</td>\n",
       "      <td>1.121994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855384</td>\n",
       "      <td>0.838502</td>\n",
       "      <td>0.989786</td>\n",
       "      <td>0.843569</td>\n",
       "      <td>1.155776</td>\n",
       "      <td>0.994813</td>\n",
       "      <td>0.996318</td>\n",
       "      <td>0.993234</td>\n",
       "      <td>0.996334</td>\n",
       "      <td>0.982111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>1.280480</td>\n",
       "      <td>1.276190</td>\n",
       "      <td>1.288912</td>\n",
       "      <td>1.291579</td>\n",
       "      <td>1.260572</td>\n",
       "      <td>1.280038</td>\n",
       "      <td>1.325512</td>\n",
       "      <td>1.288275</td>\n",
       "      <td>1.326231</td>\n",
       "      <td>1.275333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.492504</td>\n",
       "      <td>1.506321</td>\n",
       "      <td>1.333299</td>\n",
       "      <td>1.500297</td>\n",
       "      <td>1.245707</td>\n",
       "      <td>1.325703</td>\n",
       "      <td>1.327618</td>\n",
       "      <td>1.325240</td>\n",
       "      <td>1.327287</td>\n",
       "      <td>1.338556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>1.060025</td>\n",
       "      <td>1.059908</td>\n",
       "      <td>1.056354</td>\n",
       "      <td>1.054482</td>\n",
       "      <td>1.072937</td>\n",
       "      <td>1.060009</td>\n",
       "      <td>1.027649</td>\n",
       "      <td>1.052442</td>\n",
       "      <td>1.026796</td>\n",
       "      <td>1.056701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808170</td>\n",
       "      <td>0.834994</td>\n",
       "      <td>1.028176</td>\n",
       "      <td>0.824187</td>\n",
       "      <td>1.085934</td>\n",
       "      <td>1.028247</td>\n",
       "      <td>1.027980</td>\n",
       "      <td>1.027653</td>\n",
       "      <td>1.028410</td>\n",
       "      <td>1.026382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>-0.878273</td>\n",
       "      <td>-0.876218</td>\n",
       "      <td>-0.884011</td>\n",
       "      <td>-0.882976</td>\n",
       "      <td>-0.881033</td>\n",
       "      <td>-0.876016</td>\n",
       "      <td>-0.877428</td>\n",
       "      <td>-0.883691</td>\n",
       "      <td>-0.876172</td>\n",
       "      <td>-0.877518</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.636559</td>\n",
       "      <td>-0.647769</td>\n",
       "      <td>-0.874418</td>\n",
       "      <td>-0.641312</td>\n",
       "      <td>-0.892337</td>\n",
       "      <td>-0.877430</td>\n",
       "      <td>-0.875470</td>\n",
       "      <td>-0.877618</td>\n",
       "      <td>-0.875385</td>\n",
       "      <td>-0.872381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>0.864009</td>\n",
       "      <td>0.870660</td>\n",
       "      <td>0.805071</td>\n",
       "      <td>0.800712</td>\n",
       "      <td>0.901922</td>\n",
       "      <td>0.870764</td>\n",
       "      <td>0.692594</td>\n",
       "      <td>0.808347</td>\n",
       "      <td>0.693379</td>\n",
       "      <td>0.863362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045670</td>\n",
       "      <td>0.052283</td>\n",
       "      <td>0.684628</td>\n",
       "      <td>0.046264</td>\n",
       "      <td>0.929434</td>\n",
       "      <td>0.692055</td>\n",
       "      <td>0.693880</td>\n",
       "      <td>0.691212</td>\n",
       "      <td>0.693527</td>\n",
       "      <td>0.671506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>0.741530</td>\n",
       "      <td>0.757715</td>\n",
       "      <td>0.693019</td>\n",
       "      <td>0.690487</td>\n",
       "      <td>0.804252</td>\n",
       "      <td>0.753378</td>\n",
       "      <td>0.535054</td>\n",
       "      <td>0.697061</td>\n",
       "      <td>0.537864</td>\n",
       "      <td>0.755628</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.668446</td>\n",
       "      <td>-0.633230</td>\n",
       "      <td>0.522034</td>\n",
       "      <td>-0.647791</td>\n",
       "      <td>0.844424</td>\n",
       "      <td>0.535109</td>\n",
       "      <td>0.536361</td>\n",
       "      <td>0.532918</td>\n",
       "      <td>0.535635</td>\n",
       "      <td>0.504907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1.049970</td>\n",
       "      <td>1.050386</td>\n",
       "      <td>1.017431</td>\n",
       "      <td>1.013633</td>\n",
       "      <td>1.065975</td>\n",
       "      <td>1.052346</td>\n",
       "      <td>0.962966</td>\n",
       "      <td>1.015219</td>\n",
       "      <td>0.965401</td>\n",
       "      <td>1.044772</td>\n",
       "      <td>...</td>\n",
       "      <td>0.672878</td>\n",
       "      <td>0.677292</td>\n",
       "      <td>0.960809</td>\n",
       "      <td>0.673813</td>\n",
       "      <td>1.069079</td>\n",
       "      <td>0.963161</td>\n",
       "      <td>0.964591</td>\n",
       "      <td>0.962735</td>\n",
       "      <td>0.964783</td>\n",
       "      <td>0.955840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>-0.391927</td>\n",
       "      <td>-0.390098</td>\n",
       "      <td>-0.400283</td>\n",
       "      <td>-0.397292</td>\n",
       "      <td>-0.383404</td>\n",
       "      <td>-0.391727</td>\n",
       "      <td>-0.349742</td>\n",
       "      <td>-0.395626</td>\n",
       "      <td>-0.357279</td>\n",
       "      <td>-0.383171</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.401382</td>\n",
       "      <td>-0.411641</td>\n",
       "      <td>-0.365488</td>\n",
       "      <td>-0.409608</td>\n",
       "      <td>-0.349449</td>\n",
       "      <td>-0.350147</td>\n",
       "      <td>-0.358474</td>\n",
       "      <td>-0.349862</td>\n",
       "      <td>-0.359121</td>\n",
       "      <td>-0.370484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>393 rows × 400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1089.345  1063.429  962.734   965.601   914.190   1076.231  1250.068  \\\n",
       "379  1.028729  1.030634  1.004159  1.004502  1.044561  1.030239  0.965256   \n",
       "206 -0.904164 -0.908347 -0.839096 -0.835209 -0.930014 -0.908296 -0.728967   \n",
       "432  1.122145  1.130994  1.050363  1.048614  1.148173  1.129931  0.994477   \n",
       "272  1.280480  1.276190  1.288912  1.291579  1.260572  1.280038  1.325512   \n",
       "321  1.060025  1.059908  1.056354  1.054482  1.072937  1.060009  1.027649   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "37  -0.878273 -0.876218 -0.884011 -0.882976 -0.881033 -0.876016 -0.877428   \n",
       "352  0.864009  0.870660  0.805071  0.800712  0.901922  0.870764  0.692594   \n",
       "451  0.741530  0.757715  0.693019  0.690487  0.804252  0.753378  0.535054   \n",
       "416  1.049970  1.050386  1.017431  1.013633  1.065975  1.052346  0.962966   \n",
       "553 -0.391927 -0.390098 -0.400283 -0.397292 -0.383404 -0.391727 -0.349742   \n",
       "\n",
       "     960.238   1267.175  1047.108  ...  1445.173  1419.847  1285.394  \\\n",
       "379  1.005951  0.966981  1.025428  ...  0.796700  0.816613  0.965266   \n",
       "206 -0.843634 -0.730239 -0.900330  ... -0.452495 -0.447041 -0.722030   \n",
       "432  1.052448  0.996704  1.121994  ...  0.855384  0.838502  0.989786   \n",
       "272  1.288275  1.326231  1.275333  ...  1.492504  1.506321  1.333299   \n",
       "321  1.052442  1.026796  1.056701  ...  0.808170  0.834994  1.028176   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "37  -0.883691 -0.876172 -0.877518  ... -0.636559 -0.647769 -0.874418   \n",
       "352  0.808347  0.693379  0.863362  ...  0.045670  0.052283  0.684628   \n",
       "451  0.697061  0.537864  0.755628  ... -0.668446 -0.633230  0.522034   \n",
       "416  1.015219  0.965401  1.044772  ...  0.672878  0.677292  0.960809   \n",
       "553 -0.395626 -0.357279 -0.383171  ... -0.401382 -0.411641 -0.365488   \n",
       "\n",
       "     1424.528  850.046   1248.864  1269.657  1245.863  1270.902  1294.379  \n",
       "379  0.808167  1.052470  0.965650  0.966705  0.965603  0.966063  0.963941  \n",
       "206 -0.446465 -0.930544 -0.728422 -0.730134 -0.727560 -0.729684 -0.712608  \n",
       "432  0.843569  1.155776  0.994813  0.996318  0.993234  0.996334  0.982111  \n",
       "272  1.500297  1.245707  1.325703  1.327618  1.325240  1.327287  1.338556  \n",
       "321  0.824187  1.085934  1.028247  1.027980  1.027653  1.028410  1.026382  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "37  -0.641312 -0.892337 -0.877430 -0.875470 -0.877618 -0.875385 -0.872381  \n",
       "352  0.046264  0.929434  0.692055  0.693880  0.691212  0.693527  0.671506  \n",
       "451 -0.647791  0.844424  0.535109  0.536361  0.532918  0.535635  0.504907  \n",
       "416  0.673813  1.069079  0.963161  0.964591  0.962735  0.964783  0.955840  \n",
       "553 -0.409608 -0.349449 -0.350147 -0.358474 -0.349862 -0.359121 -0.370484  \n",
       "\n",
       "[393 rows x 400 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain[cols_ordered]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4dfa48-8b96-4f31-9081-1d39baf91227",
   "metadata": {},
   "source": [
    "### RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3d3e511-442e-4cf4-a107-3b8e8c7ef666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the number of selected features for RFE\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from matplotlib import pyplot\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9c4aa7-7e45-4e1e-960d-a8891cc7a46f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# https://machinelearningmastery.com/rfe-feature-selection-in-python/\n",
    "selected = []\n",
    "for i in range(2, 51, 1):\n",
    "    print(i)\n",
    "    rfe = RFE(estimator=LogisticRegression(solver = 'newton-cg'), n_features_to_select=i)\n",
    "    # fit RFE\n",
    "    rfe.fit(Xtrain[cols_ordered].values, Ytrain)\n",
    "    # summarize all features\n",
    "    selected_feat = []\n",
    "    for i in range(Xtrain[cols_ordered].shape[1]):\n",
    "        if rfe.support_[i] == True:\n",
    "            selected_feat.append(i)\n",
    "            print('Column: %d, Selected %s, Rank: %.3f' % (i, rfe.support_[i], rfe.ranking_[i]))\n",
    "        \n",
    "    print()\n",
    "    selected.append(selected_feat)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54893115-0196-4a34-9244-7327c3ad3fc2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5cd105-b166-4b8b-a33a-6000139e9806",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(selected ))\n",
    "selected.append(cols_ordered[-50:])\n",
    "selected.append(cols_ordered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2b3ae3-b433-485b-ba64-407a4f6973bf",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4737a0-0c38-4129-8bd3-06c6db467448",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa04eb1-468b-4ae4-9609-14e8e9d6b5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "solvers = ['newton-cg', 'liblinear']\n",
    "penalty = ['l2']\n",
    "c_values = [1000, 100, 10, 1.0, 0.1, 0.01, 0.001]\n",
    "lr_par = dict(solver=solvers,penalty=penalty,C=c_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac639b5-aa00-4f5e-bde6-10880db78b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [[lr, 'lr', 14]]\n",
    "par = [lr_par]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3249a265-608f-4923-8b8b-c9b9c5451946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.ml_acc import get_accuracy_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37426a51-91bb-4d4d-83d0-ed64b27c893f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ml_tools = len(par)\n",
    "ml_dicts = {}\n",
    "\n",
    "for m, par in zip(models, par):\n",
    "    key0 = str(m[1])\n",
    "    ml_dicts[key0] = {}\n",
    "    for f in selected:\n",
    "        print(cols_ordered[f])\n",
    "\n",
    "        xtr =  Xtrain[cols_ordered].iloc[:, f]\n",
    "        xte =  Xtest[cols_ordered].iloc[:, f]\n",
    "        print(xtr)\n",
    "        results = get_accuracy_ml (m[0], m[2], par, np.array(xtr), np.array(Ytrain), np.array(xte), np.array(Ytest)) # to get the accuracies for the ml model\n",
    "\n",
    "        key = str(m[1])+\",\"+str(len(f))\n",
    "        ml_dicts[key0][key] = {}\n",
    "\n",
    "        ml_dicts[key0][key]['tot_acc'] = results[0]\n",
    "        ml_dicts[key0][key]['jack_train'] = results[1]\n",
    "        ml_dicts[key0][key]['jack_test'] = results[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1304bd7a-dd4d-4ce6-8745-69540fac025a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaae12b-34bf-46f6-8a5a-9884c196363a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e6b5bd-7255-4b92-b9de-2f415f47e0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ml_rg_fs.txt', 'w') as file:\n",
    "     file.write(json.dumps(ml_dicts)) # use `json.loads` to do the reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c4f2c1-a7cc-457e-9034-bc84d1ec8521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('ml_rg_fs.txt') as f:\n",
    "    data = f.read()\n",
    "    \n",
    "ml_dicts = json.loads(data)\n",
    "\n",
    "with open('base_rg.txt') as f:\n",
    "    data = f.read()\n",
    "    \n",
    "baseDict = json.loads(data)\n",
    "baseDict['lr'].keys()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3204d7e8-9217-4d45-878d-39ef9237200b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(baseDict['lr'].keys()    )\n",
    "print(ml_dicts['lr'].keys()    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd5f1be-96e6-4d5f-b781-db4b02f11952",
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.calculate_jack import jack_SD # importing the baseline code from source.basline file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38e5fcd-f6a0-42de-a8b4-891ead0c9bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_all = []\n",
    "for m, d in zip (models, ml_dicts.keys()):\n",
    "    acc_arr = [] \n",
    "    sd_arr = [] \n",
    "\n",
    "    # print(ml_dicts[d])\n",
    "    for key in ml_dicts[d].keys():\n",
    "        acc_arr.append(ml_dicts[d][key][ 'tot_acc' ]) # append total accuracy to an array\n",
    "        sd_train = jack_SD(np.zeros( len(ml_dicts[d][key][ 'jack_train' ]) ), ml_dicts[d][key][ 'jack_train' ])[0]\n",
    "        sd_test = jack_SD(np.zeros( len(ml_dicts[d][key][ 'jack_test' ]) ), ml_dicts[d][key][ 'jack_test' ])[0]\n",
    "        sd = np.sqrt( np.array((sd_train**2)) + np.array((sd_test**2)))\n",
    "        sd_arr.append(sd) # append sd_arr to an array\n",
    "    arr_all.append([ list(ml_dicts[d].keys()), acc_arr, sd_arr])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7176c1-28fe-4a62-96e8-4a7926bbb7bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a1daa9-9415-4b03-b738-09e74f7196e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['blue', 'purple', 'green', 'orange', 'red', 'brown']\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.title( \"Precision  for different features with the SD\", fontweight ='bold', fontsize =12)\n",
    "plt.xlabel(\"Features\", fontweight ='bold', fontsize =12)\n",
    "plt.ylabel(\"Precision\", fontweight ='bold', fontsize =12)\n",
    "\n",
    "count = 0\n",
    "n = len(colors)-1\n",
    "\n",
    "space = []\n",
    "tickFeat = []\n",
    "\n",
    "for result, model, color in zip(arr_all, models, colors):\n",
    "    a = np.linspace(n*count, n*(1+count)-2,49)\n",
    "    print(a)\n",
    "    space.extend(a)\n",
    "    tickFeat.extend(result[0])\n",
    "    plt.errorbar( a, result[1], result[2], fmt='o', label =model[1], color = color)\n",
    "    count += 1\n",
    "\n",
    "plt.xticks(space, tickFeat, rotation = 'vertical',  fontsize =12)\n",
    "plt.ylim(.2, 1)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97535205-879c-4e1b-ad08-aa753c7fda53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63f2c60-45b1-4c9b-8520-93086ab1b86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_diff_all = []\n",
    "\n",
    "for m, m_key in zip (models, ml_dicts.keys()):\n",
    "    acc_diff_arr = [] \n",
    "    sd_diff_arr = [] \n",
    "    for f_key in ml_dicts[m_key].keys():\n",
    "        value = f_key.split(',')\n",
    "        acc_diff_arr.append( ml_dicts[m_key][f_key][ 'tot_acc' ] - baseDict['lr']['lr, all'][ 'tot_acc' ]  )\n",
    "\n",
    "        sd_train = jack_SD( baseDict['lr']['lr, all'][ 'jack_train' ], ml_dicts[m_key][f_key]['jack_train'] )[0]\n",
    "        sd_test = jack_SD(  baseDict['lr']['lr, all'][ 'jack_test' ],  ml_dicts[m_key][f_key]['jack_test']   )[0]\n",
    "\n",
    "        sd = np.sqrt( np.array((sd_train**2)) + np.array((sd_test**2)))\n",
    "        sd_diff_arr.append(sd) # append sd_arr to an array\n",
    "    arr_diff_all.append([ list(ml_dicts[m_key].keys()), acc_diff_arr, sd_diff_arr]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9444c457-e05f-46b6-8937-6cffae594cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['blue', 'purple', 'green', 'orange', 'red', 'brown']\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.title( \"Precision  differences for ML methods versus LR_all for feature setsD\", fontweight ='bold', fontsize =12)\n",
    "plt.xlabel(\"Features\", fontweight ='bold', fontsize =12)\n",
    "plt.ylabel(\"Precision  difference\", fontweight ='bold', fontsize =12)\n",
    "\n",
    "count = 0\n",
    "n = len(colors)-0.5\n",
    "space = []\n",
    "tickFeat = []\n",
    "\n",
    "for result, model, color in zip(arr_diff_all, models, colors):\n",
    "    a = np.linspace(n*count, n*(1+count)-2,49)\n",
    "    space.extend(a)\n",
    "    tickFeat.extend(result[0])\n",
    "    plt.errorbar( a, result[1], result[2], fmt='o', label =model[1], color = color)\n",
    "    count += 1\n",
    "    \n",
    "plt.plot(np.array(space), np.zeros(49*1), color = 'Black')        \n",
    "plt.xticks(space, tickFeat, rotation = 'vertical',  fontsize =12)\n",
    "plt.ylim(-.5, 1)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85deea14-a57f-43ab-ab70-ffb99c0dec0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71c9551-08d2-4cd7-9218-eed6f7403e60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apple_kernel",
   "language": "python",
   "name": "apple_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
